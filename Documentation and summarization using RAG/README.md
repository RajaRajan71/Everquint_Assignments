# ğŸ“„ **Document Search and Summarization using RAG**

---

## ğŸ§  **Overview**
This project implements a **Retrieval-Augmented Generation (RAG)** system for **document search and summarization** using **Large Language Models (LLMs)**.  
The system retrieves relevant documents from a text corpus using **semantic search** and generates **concise summaries** based on user queries.

The solution is built using **Hugging Face models**, **FAISS** for vector similarity search, and a **Gradio** user interface.  
The entire pipeline is designed to run in **Google Colab**.

---

## ğŸ¯ **Objective**
The objective of this project is to design a system that can:
- ğŸ” Efficiently search large text corpora  
- ğŸ“ Generate coherent and meaningful summaries  
- ğŸ¤– Utilize modern Large Language Models  

This implementation strictly follows the **assignment requirements**.

---

## ğŸ“š **Dataset**
- **ğŸ“Œ Dataset Name:** AG News  
- **ğŸŒ Source:** Hugging Face Datasets  
- **ğŸ“° Description:** A public dataset containing news articles across categories such as **World, Sports, Business, and Technology**  
- **âš ï¸ Note:** The dataset is **automatically downloaded** during execution.  
  âœ **No manual dataset is required**

---

## ğŸ› ï¸ **Models and Tools Used**
- **ğŸ”— Embedding Model:** `sentence-transformers/all-MiniLM-L6-v2`  
- **ğŸ§  Summarization Model:** `facebook/bart-large-cnn`  
- **ğŸ—‚ï¸ Vector Store:** FAISS  
- **ğŸ–¥ï¸ User Interface:** Gradio  
- **ğŸ“Š Evaluation Metrics:** ROUGE (ROUGE-1, ROUGE-2, ROUGE-L)

---

## ğŸ”„ **Methodology**
1. ğŸ“¥ Load and preprocess text data from the AG News dataset  
2. ğŸ§® Generate dense vector embeddings for each document  
3. âš¡ Index embeddings using **FAISS** for fast similarity search  
4. â“ Accept user queries and retrieve the **Top-K relevant documents**  
5. âœï¸ Generate summaries using a transformer-based summarization model  
6. ğŸ“ˆ Evaluate retrieval and summarization performance  

---

## ğŸ“Š **Evaluation**
- **ğŸ” Search Evaluation:**  
  Top-K retrieval accuracy is measured by checking whether the original document appears among the retrieved results.
  
- **ğŸ“ Summarization Evaluation:**  
  Summary quality is evaluated using **ROUGE metrics**, measuring overlap between generated summaries and reference text segments.

---

## ğŸ–¥ï¸ **User Interface**
A **Gradio-based web interface** allows users to:
- ğŸ—£ï¸ Enter information-seeking queries  
- ğŸ”¢ Adjust the number of retrieved documents (Top-K)  
- ğŸ“ Control the summary length  
- ğŸ“„ View retrieved documents and generated summaries interactively  

---

## ğŸš€ **How to Run (Google Colab)**
1. ğŸ“‚ Open the provided notebook in **Google Colab**  
2. â–¶ï¸ Run all cells sequentially  
3. â¬‡ï¸ The dataset will be downloaded automatically  
4. ğŸŒ Launch the Gradio interface  
5. ğŸ” Enter a query related to the news articles and view results  

---

## ğŸ“¦ **Requirements**
- ğŸ Python 3.8 or above  
- torch  
- transformers  
- sentence-transformers  
- datasets  
- faiss-cpu  
- gradio  
- evaluate  
- rouge-score  

---

## ğŸ’¬ **Example Queries**
- â€œSummarize recent technology newsâ€  
- â€œWhat is this article about?â€  
- â€œGive key points from the retrieved documentâ€  

---

## âš ï¸ **Challenges and Solutions**
- **Challenge:** Handling short documents during summarization  
  **âœ… Solution:** Dynamic adjustment of summary length based on input size  

- **Challenge:** Efficient retrieval from large document collections  
  **âœ… Solution:** Use of FAISS for fast and scalable vector similarity search  

---

## âœ… **Conclusion**
This project demonstrates an **effective and scalable** approach to document retrieval and summarization using modern NLP techniques.  
By combining **semantic search** with **Large Language Models**, the system provides accurate and meaningful summaries while maintaining efficiency and usability.

---
